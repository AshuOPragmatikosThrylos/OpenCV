{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube channel: ProgrammingKnowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags               integer value            description\n",
    "\n",
    "# cv2.IMREAD_COLOR          1               Loads a color image\n",
    "# cv2.IMREAD_GRAYSCALE      0               Loads image in grayscale mode\n",
    "# cv2.IMREAD_UNCHANGED      -1              Loads image such as such including the alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"NAO.jpg\",0)    #wrong filename will return None but will not give error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)  #first parameter is name of window\n",
    "cv2.waitKey(5000)        #to hold the image for 5000 ms onto a window\n",
    "cv2.destroyAllWindows()\n",
    "# if we write ...cv2.waitKey(0)....it'll not wait for any amount of seconds\n",
    "# ...it'll just close when close(top right) is clicked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing an image to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"NAO_copy.png\",img)   #first parameter is file name with extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)   #either file name with extension, or device index of the camera\n",
    "#  which we want to use is passed as the parameter\n",
    "#device index in most cases is either 0 or -1;  1 for 2nd camera ,2 for 3rd camera in case of multiple cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while loop to capture frames indefinitely\n",
    "while True:\n",
    "    ret, frame = cap.read()   # in ret...true or false will be stored a/c to availability of frame\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # first argument is the source, second is the color\n",
    "    cv2.imshow('frame_window',gray) #first parameter is name of window\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()  #after reading the variable resources need to be released\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "#cap.isOpened()    \n",
    "#while True na likhkr while cap.isOpened() bhi likh skte they... if the device index is wrong or the file passed \n",
    "#in VideoCapture().. as parameter does not  exists then the value of cap.isOpened() will be false  \n",
    "\n",
    "\n",
    "#cap.get()\n",
    "#takes property id as parameter\n",
    "#cap.get(cv2.CAP_PROP_FRAME_WIDTH)....gives the width of the frame..similarly for height ; every property has a number \n",
    "# associated with it..for width it is 3 and for height it is 4\n",
    "#there are other properties too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VideoWriter()\n",
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc,20.0,(640,480))  #first argument: name with which video is to be saved, \n",
    "                                                           #2nd argument:FOURCC code\n",
    "                                                           #3rd: number_of_frames_per_second\n",
    "                                                           #4th: size\n",
    "while True:\n",
    "    ret, frame = cap.read()   \n",
    "    if ret == True:   #i.e. if frame is available..\n",
    "        \n",
    "        out.write(frame)  #out is the instance of VideoWriter() created previously in the program\n",
    "                          #video is saved to output.avi frame by frame\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) \n",
    "        cv2.imshow('frame_window',gray) \n",
    "        \n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release() \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing, writing  on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"NAO.jpg\",1)\n",
    "#to get a black image\n",
    "# img = np.zeros([500,300,3]) #no of rows,columns,...3 indicates 3 channels B,G,R\n",
    "\n",
    "\n",
    "img = cv2.line(img,(0,0),(255,255),(0,255,0),5)  #1st parameter: image,  2nd: starting coordinates, 3rd:ending coords,\n",
    "                                                 #4th:color in BGR format, 5th: thickness of line\n",
    "img = cv2.arrowedLine(img,(0,255),(255,300),(255,0,0),5)\n",
    "img = cv2.rectangle(img,(30,30),(100,80),(0,0,255),5)  #top-left and bottom-right coords; last parameter:thickness\n",
    "                            #if in place of thickness -1 is written the rectangle will be filled with the given color\n",
    "img = cv2.rectangle(img,(300,100),(600,200),(0,255,0),-1)\n",
    "img = cv2.circle(img,(400,400),30,(0,255,0),5) #2nd parameter:centre, 3rd:radius, last:thickness\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.putText(img,'OpenCV',(10,500),font,4,(255,255,255),10,cv2.LINE_8)#3rd argument:starting point; then font style,font size, \n",
    "                                                             #font color; then thickness,linetype\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting camera parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "1280.0\n",
      "720.0\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "cap = cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "cap.set (3,1208)  #cap.get(cv2.CAP_PROP_FRAME_WIDTH)....gives the width of the frame..similarly for height\n",
    "cap.set(4,720)#  every property has a number  associated with it..for width it is 3 and for height it is 4\n",
    "#note: camera apne aukaat k hisab se hi resolution lega..aise koi bhi number cap.set() k andr pass krdene se kaam nhi hoga\n",
    "#mtlb 3000,3000 pass kroge to bhi 1280,720 hi rhega\n",
    "#2nd thing to note: resolution takes that available value that is closest to the number passed  \n",
    "#mtlb dhyaan do maine 1208 pass kiya tha pr 1280 h resolution output me\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "     \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing date, time on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set (3,1208)\n",
    "cap.set(4,720)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        \n",
    "        cv2.imshow('frame',frame)\n",
    "        localtime = time.asctime(time.localtime(time.time()))\n",
    "        frame = cv2.putText(frame,localtime,(10,50),font,1,(0,0,0),2,cv2.LINE_AA)\n",
    "        cv2.imshow('frame',frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "     \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling mouse events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listing all events in cv2 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "events = [i for i in dir(cv2) if 'EVENT' in i] #dir(cv2) shows all the classes and member function inside the cv2 package\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listening mouse events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 1: getting the coordinates of where mouse has been clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def click_event(event, x, y, flags, param): #x,y are coordinates where mouse has been clicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        strXY = str(x) + \", \" + str(y)\n",
    "        cv2.putText(img,strXY,(x,y),font,0.5,(0,0,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        blue = img[y,x,0]\n",
    "        green = img[y,x,1]\n",
    "        red = img[y,x,2]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        strBGR = str(blue) + \", \" + str(green)+ \", \" + str(red)\n",
    "        cv2.putText(img,strBGR,(x,y),font,0.5,(0,0,255),2)\n",
    "        cv2.imshow('image',img)\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 2: drawing points and connecting them using line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def click_event(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img,(x,y),3,(0,0,255),-1)\n",
    "        points.append((x,y))\n",
    "        if len(points) >= 2: # line bnane k liye km se km 2 points hone chahiye\n",
    "            cv2.line(img,points[-1],points[-2],(255,0,0),5)   #we want to join the last 2 points\n",
    "        cv2.imshow('image',img)\n",
    "        \n",
    "        \n",
    "img = cv2.imread('NAO.jpg')\n",
    "cv2.imshow('image',img)\n",
    "points = []\n",
    "\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 3: read image...click any point on the image...show the color of the point in a second window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 537 is out of bounds for axis 0 with size 480",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-246a03c50356>\u001b[0m in \u001b[0;36mclick_event\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclick_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVENT_LBUTTONDOWN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mblue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# dono notations to access an element correct h\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mgreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 537 is out of bounds for axis 0 with size 480"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        blue = img[x][y][0]  # dono notations to access an element correct h\n",
    "        green = img[x,y,1]\n",
    "        red = img[x,y,2]\n",
    "        \n",
    "#         x[0,2] = x[0][2] though the second case is more inefficient \n",
    "#         as a new temporary array is created after the first index that is subsequently indexed by 2\n",
    "        \n",
    "        cv2.circle(img, (x,y), 3, (0,0,255), -1)\n",
    "        mycolorImage = np.zeros(img.shape,np.uint8)  #datatype np.uint8 hata dene se kaam nhi krta h\n",
    "        \n",
    "        mycolorImage[:] = [blue,green,red] # [:]..means fill every point in the image with the [blue,green,red]\n",
    "        \n",
    "        cv2.imshow('color',mycolorImage)\n",
    "        \n",
    "        \n",
    "img = cv2.imread('NAO.jpg')\n",
    "cv2.imshow('image',img)\n",
    "points = []\n",
    "\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doubt....image k lower portions pe click krne se error aata h ...kyun?\n",
    "# shi color nhi pick krta h kuch points k liye...why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv2.split, cv2.resize, cv2.add, cv2.addWeighted, ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 480, 3)\n",
      "920160\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "\n",
    "print(img.shape)  # a tuple of number of rows,columns, and channels...channels means blue,green,red\n",
    "print(img.size) # Total number of pixels\n",
    "print(img.dtype) # Image datatype\n",
    "b, g, r = cv2.split(img)   #note python k split jaisa nhi h...it's gonna split the image in bgr channels\n",
    "img = cv2.merge((b,g,r))\n",
    "\n",
    "cv2.imshow('imshow',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI- Region Of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 480, 3)\n",
      "920160\n",
      "uint8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (99,95,3) into shape (0,0,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a452ee5a5358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m314\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m413\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m344\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m439\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m108\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m86\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (99,95,3) into shape (0,0,3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "\n",
    "print(img.shape)\n",
    "print(img.size) \n",
    "print(img.dtype)\n",
    "b, g, r = cv2.split(img)\n",
    "img = cv2.merge((b,g,r))\n",
    "\n",
    "item = img[314:413,344:439]\n",
    "img[66:51,108:86] = item\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('imshow',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding  images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inorder to add two images their size need to be same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "img = cv2.resize(img,(512,512))\n",
    "\n",
    "img2 = cv2.imread('hero.jpeg')\n",
    "img2 = cv2.resize(img2,(512,512))\n",
    "\n",
    "\n",
    "\n",
    "# res_img = cv2.add(img,img2)\n",
    "res_img = cv2.addWeighted(img,0.2,img2,0.8,0) #weighted addition....last parameter is the scalar we wanna add\n",
    "\n",
    "cv2.imshow('image',res_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding Trackbars to OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful when we want to change some values in image dynamically at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def cmd_trackbar(x):\n",
    "    pass\n",
    "    \n",
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('B','image',0,255,cmd_trackbar) #1st argument: trackbar name, 2nd: window name,3rd: initial value\n",
    "#(note not min value) at which the trackbar is set,4th:max value of trackbar,\n",
    "#5th:callback function whenever trackbar value changes\n",
    "cv2.createTrackbar('G','image',0,255,cmd_trackbar)\n",
    "cv2.createTrackbar('R','image',0,255,cmd_trackbar)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    \n",
    "    img[:] = [b,g,r]\n",
    "    \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a switch to a trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def cmd_trackbar(x):\n",
    "    pass\n",
    "    \n",
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('B','image',0,255,cmd_trackbar) \n",
    "cv2.createTrackbar('G','image',0,255,cmd_trackbar)\n",
    "cv2.createTrackbar('R','image',0,255,cmd_trackbar)\n",
    "\n",
    "switch = 'OFF/ON'\n",
    "cv2.createTrackbar(switch,'image',0,1,cmd_trackbar)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "    \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r] #when the position of the switch trackbar is not zero only then the changes in other trackbar \n",
    "                         #values will be reflected\n",
    " \n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing the image to color/grayscale depending on position of trackbar & printing the position of the trackbar on the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def cmd_trackbar(x):\n",
    "    pass\n",
    "    \n",
    "\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('Position','image',10,400,cmd_trackbar) \n",
    "\n",
    "\n",
    "switch = 'color/gray'\n",
    "cv2.createTrackbar(switch,'image',0,1,cmd_trackbar)\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    img = cv2.imread('NAO.jpg')\n",
    "    pos = cv2.getTrackbarPos('Position','image')\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, str(pos), (50,150), font, 6, (0,0,255), 10)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "\n",
    "    \n",
    "    if s == 0:\n",
    "        pass\n",
    "    else:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "    cv2.imshow('image',img)                     \n",
    " \n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection and Object Tracking using HSV color space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV: Hue,Saturation,Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSV se shades mil skta h BGR se nhi milta tha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hue corressponds to the color components(base pigment), hence just by selecting a range of Hue you can select any color(0-360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturation is the amount of color(depth of the pigment)(dominance of Hue)(0-100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value is basically the brightness of the color(0-100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('Tracking')\n",
    "cv2.createTrackbar('LH','Tracking',0,255,nothing)\n",
    "cv2.createTrackbar('LS','Tracking',0,255,nothing)\n",
    "cv2.createTrackbar('LV','Tracking',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('UH','Tracking',255,255,nothing)\n",
    "cv2.createTrackbar('US','Tracking',255,255,nothing)\n",
    "cv2.createTrackbar('UV','Tracking',255,255,nothing)\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('balls.jpg')\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos('LH','Tracking')\n",
    "    l_s = cv2.getTrackbarPos('LS','Tracking')\n",
    "    l_v = cv2.getTrackbarPos('LV','Tracking') #lower  #38.5Â° 76.55% 88.63%  for yellow \n",
    "                                              #...online image color picker\n",
    "                                              #        u_h     l_s    l_v\n",
    "    u_h = cv2.getTrackbarPos('UH','Tracking')\n",
    "    u_s = cv2.getTrackbarPos('US','Tracking')\n",
    "    u_v = cv2.getTrackbarPos('UV','Tracking')#upper\n",
    "    \n",
    "    \n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv,l_b,u_b)\n",
    "    \n",
    "    res = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "    \n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "object tracking is object detection in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0);\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, frame = cap.read()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Image Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding is a segmentation technique used for separating an object from its background...each pixel of an image is compared with a predefined threshold value...this comparison forms two groups...pixels having intensity lower than the threshold value and pixels having intensity higher than the threshold value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold value is global for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('gradient.png',0)\n",
    "\n",
    "#ret contains True or False \n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) #2nd param:threshold, 3rd:max value,\n",
    "                                                           #4th:threshold type\n",
    "_,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "_,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)#upto pixel value=127 pixel value will not\n",
    "    #change...will remain as that in original image but after that it will become constant at 127\n",
    "_,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)#when pixel value is less than 127..it'll\n",
    "#be reduced to zero...else it'll remain the same\n",
    "_,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "#note thresh4 inverse hokr thresh5 nhi bnaega...meaning me change h\n",
    "#agr pixel value 127 se bda h to wo zero hojaega nhi to same rhega\n",
    "\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('SIT_BINARY',thresh1)\n",
    "cv2.imshow('SIT_BINARY_INV',thresh2)\n",
    "cv2.imshow('SIT_TRUNC',thresh3)\n",
    "cv2.imshow('SIT_TOZERO',thresh4)\n",
    "cv2.imshow('SIT_TOZERO_INV',thresh5)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "threshold is not global for all pixels...it is instead calculated for a smaller region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used when the intensity of all regions in the image is not the same throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below program shows what is the problem with Simple Image Thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('sudoku.png',0)\n",
    "_,th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('th1', th1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below program shows how Adaptive thresholding solves the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('sudoku.png',0)\n",
    "th2 = cv2.adaptiveThreshold(img,255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2) \n",
    "#2nd: max value,3rd:adaptive method,4th:threshold type,5th,6th ;see description of function\n",
    "th3 = cv2.adaptiveThreshold(img,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('MEAN_C', th2)\n",
    "cv2.imshow('GAUSSIAN_C',th3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matplotlib with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('NAO.jpg',-1)\n",
    "cv2.imshow('image',img)\n",
    "\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "%matplotlib \n",
    "plt.imshow(img) # to get the matplotlib output in a separate window use %matplotlib \n",
    "# plt.xticks([]),plt.yticks([]) #hides the markings on x and y axis\n",
    "plt.axis('off') #this will do the same trick as above\n",
    "\n",
    "#OpenCV reads image in BGR format but pyplot reads in RGB format\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displaying multiple images in 1 matplotlib window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('gradient.png',0)\n",
    "\n",
    "\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY) \n",
    "_,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "_,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "_,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "_,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "\n",
    "# cv2.imshow('Image',img)\n",
    "# cv2.imshow('SIT_BINARY',thresh1)\n",
    "# cv2.imshow('SIT_BINARY_INV',thresh2)\n",
    "# cv2.imshow('SIT_TRUNC',thresh3)\n",
    "# cv2.imshow('SIT_TOZERO',thresh4)\n",
    "# cv2.imshow('SIT_TOZERO',thresh5)\n",
    "\n",
    "titles = ['Image','SIT_BINARY','SIT_BINARY_INV','SIT_TRUNC','SIT_TOZERO','SIT_TOZERO_INV']\n",
    "images = [img,thresh1,thresh2,thresh3,thresh4,thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray') #1st:no of rows,2nd:no of cols,\n",
    "                                                  #3rd:index of image\n",
    "    plt.title(titles[i])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are operations based on image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normally performed on binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary image is one that consists of pixels that can have one of exactly two colors, usually black and white"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Kernel tells us how to change the value of any given pixel by combining it with different amounts of the neighbouring pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('balls.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "#mask is applied for images which are not binary\n",
    "\n",
    "\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "dilation = cv2.dilate(mask,kernel,iterations=2) #in the masked image..there are some black dots\n",
    "# left on the white portion...to remove them we use dilation...ab bhi thoda bacha h\n",
    "#..isliye iterations\n",
    "# the bigger the shape of the kernel the better will be the result\n",
    "#but there is a problem...if any pixel under the kernel is 1 the result will be 1...\n",
    "#this increases the size of the white portion...which does not reflect the true size\n",
    "titles = ['image','mask','dilation']\n",
    "images = [img,mask,dilation]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('balls.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "kernel = np.ones((1,1), np.uint8)\n",
    "dilation = cv2.dilate(mask,kernel,iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "\n",
    "titles = ['image','mask','dilation','erosion']\n",
    "images = [img,mask,dilation,erosion]\n",
    "#a pixel in original image either 1 or 0 will be considered as 1 only if all the pixels \n",
    "#under the kernel is 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)Opening, 4)closing, 5)Morphological gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('balls.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilation = cv2.dilate(mask,kernel,iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "opening = cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernel)\n",
    "closing = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "mg = cv2.morphologyEx(mask,cv2.MORPH_GRADIENT,kernel)\n",
    "\n",
    "\n",
    "titles = ['image','mask','dilation','erosion','opening','closing','mg']\n",
    "images = [img,mask,dilation,erosion,opening,closing,mg]\n",
    "#opening is just another name of erosion followed by dilation\n",
    "#closing: dilation followed by erosion\n",
    "\n",
    "for i in range(7):\n",
    "    plt.subplot(4,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneous filter,Gaussian filter,Median filter,Bilateral filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneous filter: each output filter is the mean of its kernel neighbours...each pixel has the same weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median filter replaces each pixel's value with the median of the neighbouring pixels. used in case of 'salt and pepper noise'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian filter uses different weight kernel in both x and y direction..used to remove high frequency noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5,5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "titles = ['image','2D Convolution']\n",
    "images = [img,dst]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPF(low pass filters) help in removing noises, blurring the images\n",
    "HPF help in finding edges in the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blurring methods in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('NAO.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "kernel = np.ones((5,5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.blur(img, (5,5)) #simple averaging\n",
    "gblur = cv2.GaussianBlur(img, (5,5),0)\n",
    "\n",
    "\n",
    "titles = ['image','2D Convolution','blur()','GaussianBlur()']\n",
    "images = [img,dst,blur,gblur]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('Noise_salt_and_pepper.png')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "median = cv2.medianBlur(img1, 3 ) #here kernel size must be odd except 1\n",
    "\n",
    "titles = ['image','medianBlur()']\n",
    "images = [img1,median]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bilateral filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uptill now in the process of smoothening we smoothened the edges too\n",
    ".Sometimes we want to preserve the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('NAO.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "blur = cv2.blur(img1, (5,5))\n",
    "bilateralFilter= cv2.bilateralFilter(img1, 9,75, 75 ) \n",
    "\n",
    "titles = ['image','blur()','bilateralFilter()']\n",
    "images = [img1,blur,bilateralFilter]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Gradients and Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image gradient is the directional change in the intensity or color in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian Gradient, Sobel( in x direction), Sobel( in y direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('sudoku.png',cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img,cv2.CV_64F,ksize=1) # 2nd parameter: 64 bit float datatype\n",
    "                                            #3rd: kernel size..only odd nos\n",
    "lap = np.uint8(np.absolute(lap)) #converting to unsigned int\n",
    "\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0)#3rd param: order of derivative x\n",
    "sobelx = np.uint8(np.absolute(sobelx)) #4th:order of derivative y\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "sobely = np.uint8(np.absolute(sobely))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelx,sobely) #combining the effect of sobelx and sobely\n",
    "\n",
    "titles = ['image','Laplacian()','SobelX','SobelY','sobelCombined']\n",
    "images = [img,lap,sobelx,sobely,sobelCombined]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(3,2,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detects wide range of edges in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('sudoku.png',0)\n",
    "canny = cv2.Canny(img,100, 200)\n",
    "\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0)\n",
    "sobelx = np.uint8(np.absolute(sobelx))\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1)\n",
    "sobely = np.uint8(np.absolute(sobely))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelx,sobely)\n",
    "\n",
    "titles = ['image','sobelCombined','Canny Edge Detection']\n",
    "images = [img,sobelCombined,canny]\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1), plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
